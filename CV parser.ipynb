{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b04de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: nltk in d:\\softwares\\coding\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: scikit-learn in d:\\softwares\\coding\\lib\\site-packages (1.4.1.post1)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\softwares\\coding\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: click in d:\\softwares\\coding\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in d:\\softwares\\coding\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\softwares\\coding\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in d:\\softwares\\coding\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\softwares\\coding\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\softwares\\coding\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in d:\\softwares\\coding\\lib\\site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\softwares\\coding\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.14.6)\n",
      "Requirement already satisfied: pycparser in d:\\softwares\\coding\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.20)\n",
      "Requirement already satisfied: colorama in d:\\softwares\\coding\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: cryptography, pdfminer.six\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 3.4.8\n",
      "    Uninstalling cryptography-3.4.8:\n",
      "      Successfully uninstalled cryptography-3.4.8\n",
      "Successfully installed cryptography-42.0.5 pdfminer.six-20231228\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six nltk scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d514f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.24.1-cp39-none-win_amd64.whl (3.6 MB)\n",
      "Collecting PyMuPDFb==1.24.1\n",
      "  Downloading PyMuPDFb-1.24.1-py3-none-win_amd64.whl (24.9 MB)\n",
      "Installing collected packages: PyMuPDFb, pymupdf\n",
      "Successfully installed PyMuPDFb-1.24.1 pymupdf-1.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f032823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # Correct import for PyMuPDF\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "\n",
    "# Your code continues as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb01f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atharva Abhay Shrikhande \n",
      "Fairfax, VA | (571) 583-2625 | ashrikha@gmu.edu | https://www.linkedin.com/in/atharva-s-5525021a0/ \n",
      "\n",
      " EDUCATION \n",
      "George Mason University \n",
      "        Fairfax, VA \n",
      "Master’s in data Analytics Engineering, Applied Analytics Concentration                                                                 August 2023-May 2025 \n",
      " Relevant Coursework: Statistics for Data visualization, Operations Research, Database Management Systems, Data Mining, Big Data \n",
      "\n",
      "Savitribai Phule Pune University \n",
      "Bachelor of Technology in Mechanical Engineering  (CGPA:  3.42/4) \n",
      "\n",
      "         Pune, India \n",
      "August 2019-May 2023 \n",
      "\n",
      "CORE COMPETENCIES \n",
      "Skills: SQL, Python, R, C++, Java, HTML, CSS, Data Visualization.  \n",
      "Tools: PostgreSQL, Visio, Valentina DB, Excel, Lucid Chart, MS office 365, MS Azure, AWS (S3, EC2, Lambda, SNS, SQS) \n",
      "\n",
      "EXPERIENCE \n",
      "Inventory Analyst Intern, Precision Instrumentals, Pune, India                                                                              March 2022 – October 2022 \n",
      "• \n",
      "• \n",
      "•  Collaborated with the management team to initiate cost-saving measures, resulting in significant cost reductions per machine and \n",
      "\n",
      "Identified inventory inefficiencies and high operational costs as a key area for improvement. \n",
      "Implemented advanced Excel analytics and forecasting techniques to streamline inventory control. \n",
      "\n",
      "an 8-10% increase in revenue through optimized supply chain operations. \n",
      "\n",
      "  Engineering Analyst, KTK Machines, Pune, India                                                                                                     January 2022 – February 2022 \n",
      "Spearheaded forecasting and inventory control improvements, leading to a 15% increase in revenue by enhancing supply chain \n",
      "efficiency and reducing operational costs.  \n",
      "\n",
      "• \n",
      "\n",
      "•  Developed comprehensive reports and dynamic dashboards, enabling informed decision-making, and significantly improving \n",
      "\n",
      "• \n",
      "\n",
      "project management outcomes.  \n",
      "Fostered collaboration across departments to ensure seamless material supply chains and adherence to schedules, contributing \n",
      "to improved operational efficiency and revenue growth.  \n",
      "\n",
      "•  Delivered key insights through detailed analysis and modeling, driving strategic decisions that resulted in operational excell ence \n",
      "\n",
      "and a 15% revenue increase. \n",
      "\n",
      " ACADEMIC PROJECTS \n",
      "Electric Vehicle Data Analytics Project:                                                                                                                                                          Dec 2023 \n",
      "•  Analyzed electric vehicle (EV) distribution in Seattle, identifying King County as the leading area with a significant Tesla  presence. \n",
      "•  Utilized Python, SQL for data analysis, and R for data visualization, focusing on EV models and charging infrastructure needs . \n",
      "•  Presented data-driven insights on geographical EV  adoption trends and consumer model preferences  to inform infrastructure \n",
      "\n",
      "development. \n",
      "\n",
      "•  Highlighted the importance of charging infrastructure development in areas with high EV concentrations, supporting sustainable \n",
      "\n",
      "transportation policies. \n",
      "\n",
      "Music Store Data Analysis using SQL:                                                                                                                                                              Dec 2023       \n",
      "• \n",
      "Leveraged PostgreSQL to execute  intricate SQL queries, extracting detailed customer spending habits by artist, pinpointing the \n",
      "most favored music genres in each country, and isolating top spenders in the music category.   \n",
      "This comprehensive analysis required designing and executing multi-layered queries, showcasing deep analytical skills and an adept \n",
      "command of SQL for robust data-driven decision-making. \n",
      "\n",
      "• \n",
      "\n",
      "Fashion Retail Insights: Comprehensive 2022 Sales and Trend Analysis using Excel:                                                                          Nov 2023 \n",
      "• \n",
      "Spearheaded  data  management for  a  fashion store's annual  report,  involving meticulous data  cleaning,  transformation, and \n",
      "analysis using Excel.  \n",
      "\n",
      "•  Developed  an  interactive  pivot  table  to  dissect  sales  trends,  contributing to  targeted  marketing  strategies  and  inventory \n",
      "\n",
      "management.  \n",
      "\n",
      "•  Delivered  strategic  reports  detailing  customer  purchasing  patterns,  aiding  in  data-driven  decision-making  and  operational \n",
      "optimization while synthesizing multi-channel sales data highlighting key performance indicators and demographic insights.   \n",
      "\n",
      "LEADERSHIP AND INVOLVEMENT \n",
      "• \n",
      "\n",
      "• \n",
      "\n",
      "Jnana Prabhodini Volunteer (Since April 2015): As Lead Inventory Manager, orchestrated a pioneering \"COVID Free Lantern Shop\"  \n",
      "for the 2019 Diwali Festival, merging traditional festivities with advanced sanitization protocols. Successfully managed inventory \n",
      "and logistics, contributing to an innovative and safe celebration environment, and generated 1,50,000 INR in revenue.   \n",
      "Initiated Public Library Project: As Library Manager, spearheaded a project aimed at boosting literacy among homeless children by \n",
      "providing them with  affordable access  to  a  diverse collection of  books. Managed comprehensive tracking of  book  loans and \n",
      "maintained meticulous records, showcasing leadership, organizational skills, and a  deep  dedication to community service and \n",
      "educational empowerment. \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "resume_text = parse_resume(\"D:/ashrikha/OneDrive - George Mason University - O365 Production/Desktop/Resume/Updates Resume/AAS_resume.pdf\")\n",
    "print(resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6042dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Remove punctuation and non-alphabetic tokens\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return ' '.join(stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fea3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.9178605012786701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    sim_score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]\n",
    "    return sim_score\n",
    "\n",
    "# Assuming parse_resume and preprocess_text functions are defined elsewhere\n",
    "# and properly imported or included in your script.\n",
    "\n",
    "# Path to your resume PDF\n",
    "pdf_path = 'D:/ashrikha/OneDrive - George Mason University - O365 Production/Desktop/Resume/Updates Resume/AAS_resume.pdf'\n",
    "\n",
    "# Sample job description text\n",
    "job_description = \"\"\"(ENTER JOB DESCRIPTION HERE)\"\"\"\n",
    "\n",
    "# Parse resume text from the PDF\n",
    "resume_text = parse_resume(pdf_path)  # Ensure this function is defined and correctly implemented\n",
    "\n",
    "# Preprocess texts if necessary (if preprocess_text is not defined, ensure to define it or remove its usage)\n",
    "# preprocessed_resume = preprocess_text(resume_text)\n",
    "# preprocessed_job_description = preprocess_text(job_description)\n",
    "\n",
    "# Calculate similarity directly without preprocessing if not required\n",
    "similarity_score = calculate_similarity(resume_text, job_description)\n",
    "\n",
    "print(f\"Similarity score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a0d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
